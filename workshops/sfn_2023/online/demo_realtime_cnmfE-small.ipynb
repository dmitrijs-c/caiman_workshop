{"cells":[{"cell_type":"markdown","metadata":{"id":"_whtGCTE4REa"},"source":["## Install CaImAn if on Google Colab\n"]},{"cell_type":"code","source":["try:\n","    import google.colab\n","    import os\n","    if os.path.isdir('/content/CaImAn'):\n","        print('Doing nothing, caiman already installed')\n","        print('If you need to reinstall delete current runtime')\n","    else:\n","        !git clone --depth 1 https://github.com/flatironinstitute/CaImAn.git\n","        %cd /content/CaImAn\n","        !pip install -r requirements.txt\n","        !pip install -e .\n","        !python caiman/caimanmanager.py install --inplace\n","except:\n","    pass"],"metadata":{"id":"0vLSNXka2qrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"9d5GW91u49aG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699294763676,"user_tz":480,"elapsed":89650,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}},"outputId":"5090444a-ae90-482c-ae43-2dfe1360da40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CaImAn'...\n","remote: Enumerating objects: 227, done.\u001b[K\n","remote: Counting objects: 100% (227/227), done.\u001b[K\n","remote: Compressing objects: 100% (212/212), done.\u001b[K\n","remote: Total 227 (delta 13), reused 125 (delta 8), pack-reused 0\u001b[K\n","Receiving objects: 100% (227/227), 118.88 MiB | 12.05 MiB/s, done.\n","Resolving deltas: 100% (13/13), done.\n","Updating files: 100% (205/205), done.\n","/content/CaImAn\n","Collecting av (from -r requirements.txt (line 1))\n","  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.2.2)\n","Collecting coverage (from -r requirements.txt (line 3))\n","  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.9.0)\n","Requirement already satisfied: holoviews in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.17.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (5.5.6)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (7.34.0)\n","Collecting ipyparallel (from -r requirements.txt (line 9))\n","  Downloading ipyparallel-8.6.1-py3-none-any.whl (298 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.1/298.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyter (from -r requirements.txt (line 10))\n","  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.14.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.7.1)\n","Collecting mypy (from -r requirements.txt (line 13))\n","  Downloading mypy-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.23.5)\n","Collecting numpydoc (from -r requirements.txt (line 15))\n","  Downloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (4.8.0.76)\n","Collecting peakutils (from -r requirements.txt (line 17))\n","  Downloading PeakUtils-1.3.4-py3-none-any.whl (7.7 kB)\n","Collecting pims (from -r requirements.txt (line 18))\n","  Downloading PIMS-0.6.1.tar.gz (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (5.9.5)\n","Collecting pynwb (from -r requirements.txt (line 20))\n","  Downloading pynwb-2.5.0-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.0/134.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyqtgraph (from -r requirements.txt (line 21))\n","  Downloading pyqtgraph-0.13.3-py3-none-any.whl (960 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.0/961.0 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.19.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (1.11.3)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (2.14.0)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (2023.9.26)\n","Collecting tk (from -r requirements.txt (line 27))\n","  Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (4.66.1)\n","Collecting yapf (from -r requirements.txt (line 29))\n","  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (3.1.2)\n","Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (1.1.1)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (23.2)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (1.5.3)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (9.4.0)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (6.0.1)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (6.3.2)\n","Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->-r requirements.txt (line 2)) (2023.10.0)\n","Requirement already satisfied: param<3.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from holoviews->-r requirements.txt (line 6)) (2.0.0)\n","Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews->-r requirements.txt (line 6)) (3.0.0)\n","Requirement already satisfied: panel>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from holoviews->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from holoviews->-r requirements.txt (line 6)) (3.0.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 7)) (6.1.12)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (67.7.2)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 8))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (3.0.39)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 8)) (4.8.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from ipyparallel->-r requirements.txt (line 9)) (0.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from ipyparallel->-r requirements.txt (line 9)) (2.8.2)\n","Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.10/dist-packages (from ipyparallel->-r requirements.txt (line 9)) (23.2.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 10)) (6.5.5)\n","Collecting qtconsole (from jupyter->-r requirements.txt (line 10))\n","  Downloading qtconsole-5.5.0-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 10)) (6.1.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 10)) (6.5.4)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 10)) (7.7.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 12)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 12)) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 12)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 12)) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->-r requirements.txt (line 13)) (4.5.0)\n","Collecting mypy-extensions>=1.0.0 (from mypy->-r requirements.txt (line 13))\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->-r requirements.txt (line 13)) (2.0.1)\n","Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc->-r requirements.txt (line 15)) (5.0.2)\n","Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc->-r requirements.txt (line 15)) (0.9.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from pims->-r requirements.txt (line 18)) (2.31.6)\n","Collecting slicerator>=0.9.8 (from pims->-r requirements.txt (line 18))\n","  Downloading slicerator-1.1.0-py3-none-any.whl (10 kB)\n","Collecting hdmf>=3.9.0 (from pynwb->-r requirements.txt (line 20))\n","  Downloading hdmf-3.11.0-py3-none-any.whl (331 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.0/332.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 22)) (3.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 22)) (1.4.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 23)) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 23)) (3.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (3.20.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (2.3.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (1.59.0)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 25)) (2.14.0)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 29)) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 29)) (3.11.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 25)) (0.41.2)\n","Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from hdmf>=3.9.0->pynwb->-r requirements.txt (line 20)) (4.19.1)\n","Collecting ruamel-yaml>=0.16 (from hdmf>=3.9.0->pynwb->-r requirements.txt (line 20))\n","  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->-r requirements.txt (line 29)) (3.17.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 8)) (0.8.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->-r requirements.txt (line 2)) (2.1.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->-r requirements.txt (line 2)) (2023.3.post1)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (3.5)\n","Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (3.0.0)\n","Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (2.0.2)\n","Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (0.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (2.31.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (6.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 8)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 8)) (0.2.8)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (1.0.7)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (1.0.5)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (2.0.4)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (1.1.9)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (1.0.6)\n","Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (0.18.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (2.2.0)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (2.13.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (0.7.13)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc->-r requirements.txt (line 15)) (1.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (1.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (3.0.1)\n","Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from colorcet->holoviews->-r requirements.txt (line 6)) (0.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (3.6.6)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (3.0.9)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (5.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (4.9.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (4.11.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.2.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.8.0)\n","Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (5.9.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (1.5.0)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (23.1.0)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (1.5.8)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (1.8.2)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (0.17.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (0.17.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (1.0.0)\n","Collecting qtpy>=2.4.0 (from qtconsole->jupyter->-r requirements.txt (line 10))\n","  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (1.3.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6.0->hdmf>=3.9.0->pynwb->-r requirements.txt (line 20)) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6.0->hdmf>=3.9.0->pynwb->-r requirements.txt (line 20)) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6.0->hdmf>=3.9.0->pynwb->-r requirements.txt (line 20)) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6.0->hdmf>=3.9.0->pynwb->-r requirements.txt (line 20)) (0.10.6)\n","Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 10)) (1.24.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 10)) (0.2.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 10)) (2.18.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (2023.7.22)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml>=0.16->hdmf>=3.9.0->pynwb->-r requirements.txt (line 20))\n","  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 10)) (21.2.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 10)) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (0.5.1)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (1.0.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=0.13.1->holoviews->-r requirements.txt (line 6)) (0.1.2)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 10)) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 10)) (1.6.4)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 25)) (3.2.2)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 10)) (1.16.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 10)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 10)) (1.1.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 10)) (2.21)\n","Building wheels for collected packages: pims\n","  Building wheel for pims (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pims: filename=PIMS-0.6.1-py3-none-any.whl size=82615 sha256=e985c2ca3b0182d764a8da761285b7975b5a82886b595cd80f23a275f5539c20\n","  Stored in directory: /root/.cache/pip/wheels/cc/bf/3e/bfa77232d942f8244145f9c713b6b38f6ef04b6fb5c021c114\n","Successfully built pims\n","Installing collected packages: tk, slicerator, av, ruamel.yaml.clib, qtpy, pyqtgraph, mypy-extensions, jedi, coverage, yapf, ruamel-yaml, pims, peakutils, mypy, qtconsole, ipyparallel, hdmf, pynwb, jupyter, numpydoc\n","Successfully installed av-10.0.0 coverage-7.3.2 hdmf-3.11.0 ipyparallel-8.6.1 jedi-0.19.1 jupyter-1.0.0 mypy-1.6.1 mypy-extensions-1.0.0 numpydoc-1.6.0 peakutils-1.3.4 pims-0.6.1 pynwb-2.5.0 pyqtgraph-0.13.3 qtconsole-5.5.0 qtpy-2.4.1 ruamel-yaml-0.18.5 ruamel.yaml.clib-0.2.8 slicerator-1.1.0 tk-0.1.0 yapf-0.40.2\n","Obtaining file:///content/CaImAn\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: caiman\n","  Building editable for caiman (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for caiman: filename=caiman-1.9.16-0.editable-cp310-cp310-linux_x86_64.whl size=14576 sha256=7510d17e617db37fa184660f02321f07f821e93808cadae4b0aeabcd4d4a7789\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-f0zbrflt/wheels/84/de/89/3810d06a885f45926af682c35d742d3a2dc8551efb7a6ef9e9\n","Successfully built caiman\n","Installing collected packages: caiman\n","Successfully installed caiman-1.9.16\n","error: XDG_RUNTIME_DIR not set in the environment.\n","ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n","ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n","ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n","ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n","ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n","ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n","ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n","ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n","ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","2023-11-06 18:19:18.308181: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-06 18:19:18.308231: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-06 18:19:18.308269: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-06 18:19:18.315977: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-06 18:19:19.700877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/caimanmanager\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/CaImAn/caiman/caimanmanager.py\", line 234, in main\n","    do_install_to(cfg.userdir, cfg.inplace, cfg.force)\n","  File \"/content/CaImAn/caiman/caimanmanager.py\", line 60, in do_install_to\n","    shutil.copytree(sourcedir_base, targdir)\n","  File \"/usr/lib/python3.10/shutil.py\", line 557, in copytree\n","    with os.scandir(src) as itr:\n","FileNotFoundError: [Errno 2] No such file or directory: '/usr/share/caiman'\n"]}],"source":["try:\n","    import google.colab\n","    import os\n","    if os.path.isdir('/content/CaImAn'):\n","        print('Doing nothing, caiman already installed')\n","        print('If you need to reinstall delete current runtime')\n","    else:\n","        !git clone --depth 1 https://github.com/flatironinstitute/CaImAn.git\n","        %cd /content/CaImAn\n","        !pip install -r requirements.txt\n","        !pip install -e .\n","        !caimanmanager install\n","except:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"F3Ib6_z24m3D"},"source":["## Pipeline for real-time processing of microendoscopic data with CaImAn\n","This demo presents 3 approaches for processing microendoscopic data in real time using CaImAn.\n","1. Sufficiently long initialization phase to identify all ROIs  followed by tracking\n","2. Short initalization phase followed by online processing using OnACID-E\n","3. Short initalization phase followed by online processing using Ring-CNN+OnACID\n","\n","All approached include:\n","- Motion Correction using the NoRMCorre algorithm\n","- Source extraction using a variant of the CNMF algorithm\n","- Deconvolution using the OASIS algorithm\n","\n","OnACID-E and Ring-CNN further include\n","- Detection of new components\n","- Refinement of neural spatial footprints (and background in the case of OnACID-E)\n","\n","@author: Johannes Friedrich @j-friedrich. Special thanks to Bernardo Sabatini and his lab at Harvard Medical School for sharing the data used in this demo."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6Jqmke_q4REb","colab":{"base_uri":"https://localhost:8080/","height":42},"executionInfo":{"status":"ok","timestamp":1699294797713,"user_tz":480,"elapsed":7612,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}},"outputId":"8b35fd80-c16d-4487-803f-074fe4500b57"},"outputs":[{"output_type":"display_data","data":{"application/javascript":["(function(root) {\n","  function now() {\n","    return new Date();\n","  }\n","\n","  var force = true;\n","  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n","  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n","  var reloading = false;\n","  var Bokeh = root.Bokeh;\n","  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n","\n","  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n","    root._bokeh_timeout = Date.now() + 5000;\n","    root._bokeh_failed_load = false;\n","  }\n","\n","  function run_callbacks() {\n","    try {\n","      root._bokeh_onload_callbacks.forEach(function(callback) {\n","        if (callback != null)\n","          callback();\n","      });\n","    } finally {\n","      delete root._bokeh_onload_callbacks;\n","    }\n","    console.debug(\"Bokeh: all callbacks have finished\");\n","  }\n","\n","  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n","    if (css_urls == null) css_urls = [];\n","    if (js_urls == null) js_urls = [];\n","    if (js_modules == null) js_modules = [];\n","    if (js_exports == null) js_exports = {};\n","\n","    root._bokeh_onload_callbacks.push(callback);\n","\n","    if (root._bokeh_is_loading > 0) {\n","      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n","      return null;\n","    }\n","    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n","      run_callbacks();\n","      return null;\n","    }\n","    if (!reloading) {\n","      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n","    }\n","\n","    function on_load() {\n","      root._bokeh_is_loading--;\n","      if (root._bokeh_is_loading === 0) {\n","        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n","        run_callbacks()\n","      }\n","    }\n","    window._bokeh_on_load = on_load\n","\n","    function on_error() {\n","      console.error(\"failed to load \" + url);\n","    }\n","\n","    var skip = [];\n","    if (window.requirejs) {\n","      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n","      require([\"jspanel\"], function(jsPanel) {\n","\twindow.jsPanel = jsPanel\n","\ton_load()\n","      })\n","      require([\"jspanel-modal\"], function() {\n","\ton_load()\n","      })\n","      require([\"jspanel-tooltip\"], function() {\n","\ton_load()\n","      })\n","      require([\"jspanel-hint\"], function() {\n","\ton_load()\n","      })\n","      require([\"jspanel-layout\"], function() {\n","\ton_load()\n","      })\n","      require([\"jspanel-contextmenu\"], function() {\n","\ton_load()\n","      })\n","      require([\"jspanel-dock\"], function() {\n","\ton_load()\n","      })\n","      require([\"gridstack\"], function(GridStack) {\n","\twindow.GridStack = GridStack\n","\ton_load()\n","      })\n","      require([\"notyf\"], function() {\n","\ton_load()\n","      })\n","      root._bokeh_is_loading = css_urls.length + 9;\n","    } else {\n","      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n","    }\n","\n","    var existing_stylesheets = []\n","    var links = document.getElementsByTagName('link')\n","    for (var i = 0; i < links.length; i++) {\n","      var link = links[i]\n","      if (link.href != null) {\n","\texisting_stylesheets.push(link.href)\n","      }\n","    }\n","    for (var i = 0; i < css_urls.length; i++) {\n","      var url = css_urls[i];\n","      if (existing_stylesheets.indexOf(url) !== -1) {\n","\ton_load()\n","\tcontinue;\n","      }\n","      const element = document.createElement(\"link\");\n","      element.onload = on_load;\n","      element.onerror = on_error;\n","      element.rel = \"stylesheet\";\n","      element.type = \"text/css\";\n","      element.href = url;\n","      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n","      document.body.appendChild(element);\n","    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n","      var urls = ['https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n","      for (var i = 0; i < urls.length; i++) {\n","        skip.push(urls[i])\n","      }\n","    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n","      var urls = ['https://cdn.holoviz.org/panel/1.3.0/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n","      for (var i = 0; i < urls.length; i++) {\n","        skip.push(urls[i])\n","      }\n","    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n","      var urls = ['https://cdn.holoviz.org/panel/1.3.0/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n","      for (var i = 0; i < urls.length; i++) {\n","        skip.push(urls[i])\n","      }\n","    }    var existing_scripts = []\n","    var scripts = document.getElementsByTagName('script')\n","    for (var i = 0; i < scripts.length; i++) {\n","      var script = scripts[i]\n","      if (script.src != null) {\n","\texisting_scripts.push(script.src)\n","      }\n","    }\n","    for (var i = 0; i < js_urls.length; i++) {\n","      var url = js_urls[i];\n","      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n","\tif (!window.requirejs) {\n","\t  on_load();\n","\t}\n","\tcontinue;\n","      }\n","      var element = document.createElement('script');\n","      element.onload = on_load;\n","      element.onerror = on_error;\n","      element.async = false;\n","      element.src = url;\n","      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n","      document.head.appendChild(element);\n","    }\n","    for (var i = 0; i < js_modules.length; i++) {\n","      var url = js_modules[i];\n","      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n","\tif (!window.requirejs) {\n","\t  on_load();\n","\t}\n","\tcontinue;\n","      }\n","      var element = document.createElement('script');\n","      element.onload = on_load;\n","      element.onerror = on_error;\n","      element.async = false;\n","      element.src = url;\n","      element.type = \"module\";\n","      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n","      document.head.appendChild(element);\n","    }\n","    for (const name in js_exports) {\n","      var url = js_exports[name];\n","      if (skip.indexOf(url) >= 0 || root[name] != null) {\n","\tif (!window.requirejs) {\n","\t  on_load();\n","\t}\n","\tcontinue;\n","      }\n","      var element = document.createElement('script');\n","      element.onerror = on_error;\n","      element.async = false;\n","      element.type = \"module\";\n","      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n","      element.textContent = `\n","      import ${name} from \"${url}\"\n","      window.${name} = ${name}\n","      window._bokeh_on_load()\n","      `\n","      document.head.appendChild(element);\n","    }\n","    if (!js_urls.length && !js_modules.length) {\n","      on_load()\n","    }\n","  };\n","\n","  function inject_raw_css(css) {\n","    const element = document.createElement(\"style\");\n","    element.appendChild(document.createTextNode(css));\n","    document.body.appendChild(element);\n","  }\n","\n","  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.3.0/dist/panel.min.js\"];\n","  var js_modules = [];\n","  var js_exports = {};\n","  var css_urls = [];\n","  var inline_js = [    function(Bokeh) {\n","      Bokeh.set_log_level(\"info\");\n","    },\n","function(Bokeh) {} // ensure no trailing comma for IE\n","  ];\n","\n","  function run_inline_js() {\n","    if ((root.Bokeh !== undefined) || (force === true)) {\n","      for (var i = 0; i < inline_js.length; i++) {\n","        inline_js[i].call(root, root.Bokeh);\n","      }\n","      // Cache old bokeh versions\n","      if (Bokeh != undefined && !reloading) {\n","\tvar NewBokeh = root.Bokeh;\n","\tif (Bokeh.versions === undefined) {\n","\t  Bokeh.versions = new Map();\n","\t}\n","\tif (NewBokeh.version !== Bokeh.version) {\n","\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n","\t}\n","\troot.Bokeh = Bokeh;\n","      }} else if (Date.now() < root._bokeh_timeout) {\n","      setTimeout(run_inline_js, 100);\n","    } else if (!root._bokeh_failed_load) {\n","      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n","      root._bokeh_failed_load = true;\n","    }\n","    root._bokeh_is_initializing = false\n","  }\n","\n","  function load_or_wait() {\n","    // Implement a backoff loop that tries to ensure we do not load multiple\n","    // versions of Bokeh and its dependencies at the same time.\n","    // In recent versions we use the root._bokeh_is_initializing flag\n","    // to determine whether there is an ongoing attempt to initialize\n","    // bokeh, however for backward compatibility we also try to ensure\n","    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n","    // before older versions are fully initialized.\n","    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n","      root._bokeh_is_initializing = false;\n","      root._bokeh_onload_callbacks = undefined;\n","      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n","      load_or_wait();\n","    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n","      setTimeout(load_or_wait, 100);\n","    } else {\n","      Bokeh = root.Bokeh;\n","      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n","      root._bokeh_is_initializing = true\n","      root._bokeh_onload_callbacks = []\n","      if (!reloading && (!bokeh_loaded || is_dev)) {\n","\troot.Bokeh = undefined;\n","      }\n","      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n","\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n","\trun_inline_js();\n","      });\n","    }\n","  }\n","  // Give older versions of the autoload script a head-start to ensure\n","  // they initialize before we start loading newer version.\n","  setTimeout(load_or_wait, 100)\n","}(window));"],"application/vnd.holoviews_load.v0+json":"(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.0/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.0/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.3.0/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.holoviews_load.v0+json":"\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n","application/javascript":["\n","if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n","  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n","}\n","\n","\n","    function JupyterCommManager() {\n","    }\n","\n","    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n","      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n","        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n","        comm_manager.register_target(comm_id, function(comm) {\n","          comm.on_msg(msg_handler);\n","        });\n","      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n","        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n","          comm.onMsg = msg_handler;\n","        });\n","      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n","        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n","          var messages = comm.messages[Symbol.asyncIterator]();\n","          function processIteratorResult(result) {\n","            var message = result.value;\n","            console.log(message)\n","            var content = {data: message.data, comm_id};\n","            var buffers = []\n","            for (var buffer of message.buffers || []) {\n","              buffers.push(new DataView(buffer))\n","            }\n","            var metadata = message.metadata || {};\n","            var msg = {content, buffers, metadata}\n","            msg_handler(msg);\n","            return messages.next().then(processIteratorResult);\n","          }\n","          return messages.next().then(processIteratorResult);\n","        })\n","      }\n","    }\n","\n","    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n","      if (comm_id in window.PyViz.comms) {\n","        return window.PyViz.comms[comm_id];\n","      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n","        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n","        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n","        if (msg_handler) {\n","          comm.on_msg(msg_handler);\n","        }\n","      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n","        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n","        comm.open();\n","        if (msg_handler) {\n","          comm.onMsg = msg_handler;\n","        }\n","      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n","        var comm_promise = google.colab.kernel.comms.open(comm_id)\n","        comm_promise.then((comm) => {\n","          window.PyViz.comms[comm_id] = comm;\n","          if (msg_handler) {\n","            var messages = comm.messages[Symbol.asyncIterator]();\n","            function processIteratorResult(result) {\n","              var message = result.value;\n","              var content = {data: message.data};\n","              var metadata = message.metadata || {comm_id};\n","              var msg = {content, metadata}\n","              msg_handler(msg);\n","              return messages.next().then(processIteratorResult);\n","            }\n","            return messages.next().then(processIteratorResult);\n","          }\n","        }) \n","        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n","          return comm_promise.then((comm) => {\n","            comm.send(data, metadata, buffers, disposeOnDone);\n","          });\n","        };\n","        var comm = {\n","          send: sendClosure\n","        };\n","      }\n","      window.PyViz.comms[comm_id] = comm;\n","      return comm;\n","    }\n","    window.PyViz.comm_manager = new JupyterCommManager();\n","    \n","\n","\n","var JS_MIME_TYPE = 'application/javascript';\n","var HTML_MIME_TYPE = 'text/html';\n","var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n","var CLASS_NAME = 'output';\n","\n","/**\n"," * Render data to the DOM node\n"," */\n","function render(props, node) {\n","  var div = document.createElement(\"div\");\n","  var script = document.createElement(\"script\");\n","  node.appendChild(div);\n","  node.appendChild(script);\n","}\n","\n","/**\n"," * Handle when a new output is added\n"," */\n","function handle_add_output(event, handle) {\n","  var output_area = handle.output_area;\n","  var output = handle.output;\n","  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n","    return\n","  }\n","  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n","  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n","  if (id !== undefined) {\n","    var nchildren = toinsert.length;\n","    var html_node = toinsert[nchildren-1].children[0];\n","    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n","    var scripts = [];\n","    var nodelist = html_node.querySelectorAll(\"script\");\n","    for (var i in nodelist) {\n","      if (nodelist.hasOwnProperty(i)) {\n","        scripts.push(nodelist[i])\n","      }\n","    }\n","\n","    scripts.forEach( function (oldScript) {\n","      var newScript = document.createElement(\"script\");\n","      var attrs = [];\n","      var nodemap = oldScript.attributes;\n","      for (var j in nodemap) {\n","        if (nodemap.hasOwnProperty(j)) {\n","          attrs.push(nodemap[j])\n","        }\n","      }\n","      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n","      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n","      oldScript.parentNode.replaceChild(newScript, oldScript);\n","    });\n","    if (JS_MIME_TYPE in output.data) {\n","      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n","    }\n","    output_area._hv_plot_id = id;\n","    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n","      window.PyViz.plot_index[id] = Bokeh.index[id];\n","    } else {\n","      window.PyViz.plot_index[id] = null;\n","    }\n","  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n","    var bk_div = document.createElement(\"div\");\n","    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n","    var script_attrs = bk_div.children[0].attributes;\n","    for (var i = 0; i < script_attrs.length; i++) {\n","      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n","    }\n","    // store reference to server id on output_area\n","    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n","  }\n","}\n","\n","/**\n"," * Handle when an output is cleared or removed\n"," */\n","function handle_clear_output(event, handle) {\n","  var id = handle.cell.output_area._hv_plot_id;\n","  var server_id = handle.cell.output_area._bokeh_server_id;\n","  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n","  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n","  if (server_id !== null) {\n","    comm.send({event_type: 'server_delete', 'id': server_id});\n","    return;\n","  } else if (comm !== null) {\n","    comm.send({event_type: 'delete', 'id': id});\n","  }\n","  delete PyViz.plot_index[id];\n","  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n","    var doc = window.Bokeh.index[id].model.document\n","    doc.clear();\n","    const i = window.Bokeh.documents.indexOf(doc);\n","    if (i > -1) {\n","      window.Bokeh.documents.splice(i, 1);\n","    }\n","  }\n","}\n","\n","/**\n"," * Handle kernel restart event\n"," */\n","function handle_kernel_cleanup(event, handle) {\n","  delete PyViz.comms[\"hv-extension-comm\"];\n","  window.PyViz.plot_index = {}\n","}\n","\n","/**\n"," * Handle update_display_data messages\n"," */\n","function handle_update_output(event, handle) {\n","  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n","  handle_add_output(event, handle)\n","}\n","\n","function register_renderer(events, OutputArea) {\n","  function append_mime(data, metadata, element) {\n","    // create a DOM node to render to\n","    var toinsert = this.create_output_subarea(\n","    metadata,\n","    CLASS_NAME,\n","    EXEC_MIME_TYPE\n","    );\n","    this.keyboard_manager.register_events(toinsert);\n","    // Render to node\n","    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n","    render(props, toinsert[0]);\n","    element.append(toinsert);\n","    return toinsert\n","  }\n","\n","  events.on('output_added.OutputArea', handle_add_output);\n","  events.on('output_updated.OutputArea', handle_update_output);\n","  events.on('clear_output.CodeCell', handle_clear_output);\n","  events.on('delete.Cell', handle_clear_output);\n","  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n","\n","  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n","    safe: true,\n","    index: 0\n","  });\n","}\n","\n","if (window.Jupyter !== undefined) {\n","  try {\n","    var events = require('base/js/events');\n","    var OutputArea = require('notebook/js/outputarea').OutputArea;\n","    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n","      register_renderer(events, OutputArea);\n","    }\n","  } catch(err) {\n","  }\n","}\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>*[data-root-id],\n","*[data-root-id] > * {\n","  box-sizing: border-box;\n","  font-family: var(--jp-ui-font-family);\n","  font-size: var(--jp-ui-font-size1);\n","  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n","}\n","\n","/* Override VSCode background color */\n",".cell-output-ipywidget-background:has(\n","    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n","  ),\n",".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n","  background-color: transparent !important;\n","}\n","</style>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","<div class=\"logo-block\">\n","<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n","AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n","VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n","tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n","nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n","ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n","lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n","G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n","x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n","GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n","4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n","BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n","QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n","OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n","2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n","zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n","HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n","noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n","KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n","Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n","V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n","UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n","71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n","ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n","aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n","1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n","9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n","CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n","xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n","e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n","y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n","2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n","eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n","idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n","VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n","NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n","NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n","fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n","HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n","Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n","sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n","JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n","0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n","18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n","efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n","KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n","lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n","nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n","llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n","ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n","xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n","Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n","T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n","Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n","2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n","nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n","b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n","/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n","0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n","aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n","sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n","oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n","q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n","9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n","SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n","N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n","zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n","EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n","roTBs2RqAAAAAElFTkSuQmCC'\n","     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n","\n","\n","  <img src='data:image/png;base64,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'\n","       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n","  \n","\n","\n","\n","\n","</div>\n"]},"metadata":{}}],"source":["import bokeh.plotting as bpl\n","import cv2\n","import holoviews as hv\n","import logging\n","import matplotlib.pyplot as plt\n","from multiprocessing import Process, Queue, set_start_method\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","from sys import platform\n","import tensorflow as tf\n","from time import time, sleep\n","\n","try:\n","    if __IPYTHON__:\n","        get_ipython().run_line_magic('load_ext', 'autoreload')\n","        get_ipython().run_line_magic('autoreload', '2')\n","except NameError:\n","    pass\n","\n","logging.basicConfig(format=\n","                          \"%(relativeCreated)12d [%(filename)s:%(funcName)10s():%(lineno)s] [%(process)d] %(message)s\",\n","                    # filename=\"/tmp/caiman.log\",\n","                    level=logging.WARNING)\n","\n","import caiman as cm\n","from caiman.source_extraction import cnmf\n","from caiman.source_extraction.cnmf.online_cnmf import demix1p\n","from caiman.utils.nn_models import (fit_NL_model, create_LN_model, quantile_loss, rate_scheduler)\n","from caiman.utils.utils import download_demo\n","\n","bpl.output_notebook()\n","hv.notebook_extension('bokeh')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"WLE62UMv4REc","executionInfo":{"status":"ok","timestamp":1699294798121,"user_tz":480,"elapsed":415,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}}},"outputs":[],"source":["if platform in ('linux', 'darwin'):\n","    set_start_method('fork')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"h6EFva_-4REc","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1699294798526,"user_tz":480,"elapsed":411,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}},"outputId":"5616690d-36fd-4b72-add8-135f55b71584"},"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8b845cc16f69>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'foo.tif'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'blood_vessel_10Hz.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# equivalent to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/CaImAn/caiman/utils/utils.py\u001b[0m in \u001b[0;36mdownload_demo\u001b[0;34m(name, save_folder)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {name} already downloaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot find the example_movies folder in your caiman_datadir - did you make one with caimanmanager?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath_movie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Cannot find the example_movies folder in your caiman_datadir - did you make one with caimanmanager?"]}],"source":["import h5py\n","fname = 'foo.tif'\n","with h5py.File(download_demo('blood_vessel_10Hz.mat')) as f:\n","    cm.movie(f['Y'][:3000,64:-64,64:-64]).save(fname)\n","# equivalent to\n","# cm.load(download_demo('blood_vessel_10Hz.mat'), var_name_hdf5='Y',\n","#         subindices=slice(0,3000), bottom=64, top=64, left=64, right=64).save(fname)"]},{"cell_type":"markdown","metadata":{"id":"Fx7OMzf64REd"},"source":["Below, we mention the code that can be used to read directly from the camera.<br/>\n","In this demo we simulate it by reading frame by frame from a file instead, so that everybody can execute the demo.\n","The `download_demo` function will download the file (if not already present) and store it inside your caiman_data/example_movies folder. We create an `iterator` over the file that returns the next imaged frame when calling `next(iterator)`.<br/>\n","Here we define a function that creates and returns such an iterator. It works for both, a file or an imaging device."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"huGv0V714REd","executionInfo":{"status":"aborted","timestamp":1699294798527,"user_tz":480,"elapsed":6,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}}},"outputs":[],"source":["def get_iterator(device=0, fr=None):\n","    \"\"\"\n","    device: device number (int) or filename (string) for reading from camera or file respectively\n","    fr: frame rate\n","    \"\"\"\n","    if isinstance(device, int):  # capture from camera\n","        def capture_iter(device=device, fr=fr):\n","            cap = cv2.VideoCapture(device)\n","            if fr is not None:  # set frame rate\n","                cap.set(cv2.CAP_PROP_FPS, fr)\n","            while True:\n","                yield cv2.cvtColor(cap.read()[1], cv2.COLOR_BGR2GRAY)\n","        iterator = capture_iter(device, fr)\n","    else:  # read frame by frame from file\n","        iterator = cm.base.movies.load_iter(device, var_name_hdf5='Y')\n","    return iterator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AQPDlJl4REd","executionInfo":{"status":"aborted","timestamp":1699294798527,"user_tz":480,"elapsed":6,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}}},"outputs":[],"source":["# iterator = get_iterator(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6G4w9Ie4REe","executionInfo":{"status":"aborted","timestamp":1699294798527,"user_tz":480,"elapsed":6,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}}},"outputs":[],"source":["# plt.imshow(next(iterator))"]},{"cell_type":"markdown","metadata":{"id":"p6_F_Py-4REe"},"source":["## 1. Sufficiently long initialization phase to identify all ROIs  followed by tracking"]},{"cell_type":"markdown","metadata":{"id":"LxtdLepq4REe"},"source":["### Record for few minutes\n","The `download_demo` function will download the file (if not already present) and store it inside your caiman_data/example_movies folder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmdcY8tY4REf","executionInfo":{"status":"aborted","timestamp":1699294798527,"user_tz":480,"elapsed":6,"user":{"displayName":"Johannes Friedrich","userId":"13117917344201741505"}}},"outputs":[],"source":["init_batch = 1500  # number of frames to use for initialization\n","T = 3000           # total number of frames\n","fr = 10            # frame rate (Hz)\n","\n","iterator = get_iterator(fname)\n","\n","m = cm.movie(np.array([next(iterator) for t in range(init_batch)], dtype='float32'))"]},{"cell_type":"markdown","metadata":{"id":"FcofQux84REf"},"source":["### Take a break from imaging to process recorded data\n","Taking a break to keep this demo simple. One could in parallel continue to save the otherwise \"lost\" frames to disk if one was not only intersted in the real-time experiment but post-analysis of the entire session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_I3GsUl4REf"},"outputs":[],"source":["fname_init = m.save('init.mmap', order='C')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUFAYYv74REf"},"outputs":[],"source":["params_dict = {'fnames': fname_init,            # filename(s) to be processed\n","               'fr': fr,                        # frame rate (Hz)\n","               'method_init': 'corr_pnr',       # use corr_pnr for initialization of 1p data\n","               'K': None,                       # upper bound on number of components per patch, in general None\n","               'gSig': (3, 3),                  # gaussian width of a 2D gaussian kernel, which approximates a neuron\n","               'gSiz': (13, 13),                # average diameter of a neuron, in general 4*gSig+1\n","               'merge_thr': .65,                # merging threshold, max correlation allowed\n","               'p': 1,                          # order of the autoregressive system\n","               'tsub': 1,                       # downsampling factor in time for initialization\n","               'ssub': 1,                       # downsampling factor in space for initialization\n","               'only_init': True,               # set it to True to run CNMF-E\n","               'nb': 0,                         # number of background components (rank) if positive,\n","                                                # set it to 0 to use the exact ring model and return background as b0 and W\n","               'min_corr': .7,                  # min peak value from correlation image\n","               'min_pnr': 7,                    # min peak to noise ration from PNR image\n","               'normalize_init': False,         # whether to equalize the movies during initialization\n","               'ring_size_factor': 1.4,         # radius of ring is gSiz*ring_size_factor\n","               'center_psf': True,              # whether to center the Gaussian convolution kernel, set it to True for 1 photon\n","               'init_iter': 1,                  # number of iterations during corr_pnr (1p) initialization\n","               's_min': -10,                    # minimum spike threshold\n","               'init_batch': init_batch,        # length of mini batch for initialization\n","               'init_method': 'cnmf',           # initialization method for initial batch\n","               'use_dense': False,              # flag for representation and storing of A and b\n","               'motion_correct': True,          # flag for performing motion correction\n","               'gSig_filt': (3, 3),             # size of high pass spatial filtering, used in 1p data\n","                                                # the next 3 lines turn off shape updates during online processing\n","               'update_num_comps': False,       # whether to search for new components\n","               'batch_update_suff_stat': True,  # whether to update sufficient statistics in batch mode\n","               'update_freq' : -np.inf}         # update each shapes and sufficient statistics every X frames\n","opts = cnmf.params.CNMFParams(params_dict=params_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uhXsHUN4REf"},"outputs":[],"source":["cnm1 = cnmf.online_cnmf.OnACID(dview=None, params=opts)\n","cnm1.initialize_online(T=T)"]},{"cell_type":"markdown","metadata":{"id":"kqDEa3w74REg"},"source":["#### Alternatively we could initialize using any other pipeline that models the movie data as $Y=A C + B + N$ with spatial components $A$, temporal components $C$, background $B$, and noise $N$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWT14xqq4REg"},"outputs":[],"source":["# def init_from_other_pipeline(cnm, movie, A, C, T):\n","#     Yr = movie.reshape(len(m), -1).T\n","#     e = cnm.estimates\n","#     e.A = A\n","#     e.C = np.zeros_like(C)\n","#     e.bl = np.zeros(len(C))\n","#     e.c1 = np.zeros(len(C))\n","#     e.g = np.zeros((len(C), 1))\n","#     e.neurons_sn = np.zeros(len(C))\n","#     e.S = np.zeros_like(C)\n","#     e.lam = np.zeros(len(C))\n","#     for i,c in enumerate(C):\n","#         e.C[i], e.bl[i], e.c1[i], e.g[i], e.neurons_sn[i], e.S[i], e.lam[i] = (\n","#         cm.source_extraction.cnmf.deconvolution.constrained_foopsi(\n","#         c, p=1, bas_nonneg=False, noise_method='mean', fudge_factor=.97, optimize_g=5))\n","#     e.YrA = C-e.C\n","#     e.W, e.b = cm.source_extraction.cnmf.initialization.compute_W(\n","#         Yr, e.A, e.C, movie.shape[1:],\n","#         cnm.params.get('init', 'gSiz')[0] * cnm.params.get('init', 'ring_size_factor'),\n","#         ssub=cnm.params.get('init', 'ssub_B'))\n","#     cnm._prepare_object(Yr, T)\n","#     return cnm\n","#\n","# replace A,C with the results of your pipeline, and m with your initialization movie\n","# A, C = cnm.estimates.Ab, cnm.estimates.noisyC[:cnm.N]\n","# cnm = cnmf.online_cnmf.OnACID(dview=None, params=opts)\n","# cnm = init_from_other_pipeline(cnm, m, A, C, T)"]},{"cell_type":"markdown","metadata":{"id":"YhwALWHT4REg"},"source":["### Start real-time processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9DwBijC4REg"},"outputs":[],"source":["cnm1.t_read = []\n","cnm1.t_fit = []\n","for t in range(init_batch, T):\n","    # read frame\n","    t0 = time()\n","    frame = next(iterator)\n","    cnm1.t_read.append(time()-t0)\n","    # motion correct\n","    t0 = time()\n","    frame = cnm1.mc_next(t, frame.astype(np.float32))\n","    cnm1.t_motion.append(time()-t0)\n","    # fit\n","    t0 = time()\n","    cnm1.fit_next(t, frame.ravel(order='F'))\n","    cnm1.t_fit.append(time()-t0)\n","    # add code to display whatever you want in order to guide the closed-loop experiment below\n","    # e.g. print the indices of neurons that just spiked\n","#     print('\\r', ' '*200, end=\"\\r\")\n","#     for i, o in enumerate(cnm1.estimates.OASISinstances):\n","#         if o.get_l_of_last_pool() == 1:\n","#             print(i, end=' ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amB2sm4E4REg"},"outputs":[],"source":["del iterator"]},{"cell_type":"markdown","metadata":{"id":"k5QCrr8R4REh"},"source":["### Plot results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJTp_eUM4REh"},"outputs":[],"source":["# calculate time one would have to wait for next frame to arrive if reading directly from camera\n","t_all = np.cumsum(cnm1.t_read) + np.cumsum(cnm1.t_motion) + np.cumsum(cnm1.t_fit)\n","\n","t_wait=[1]\n","t_wait_total=0\n","for i in range(1, T-init_batch):\n","    t_wait.append(max(i/fr - t_all[i-1]-t_wait_total, 0))\n","    t_wait_total += t_wait[-1]\n","realtime = np.array(t_wait)>0\n","print('%g%s processed in real time. %g/%g frames' %\n","      (100 * realtime.sum() / (T-init_batch), '%', realtime.sum(), T-init_batch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfCiYEOL4REh"},"outputs":[],"source":["plt.figure(figsize=(12,4))\n","for i, f in enumerate((lambda a: 1000*np.array(a), np.cumsum)):\n","    plt.subplot(1,2,1+i)\n","    plt.stackplot(np.arange(T-init_batch), f(cnm1.t_read), f(cnm1.t_motion),\n","                  f(cnm1.t_fit))\n","    plt.gca().add_artist(plt.legend(labels=['read', 'motion', 'process'], loc=2))\n","    plt.title('Processing time allocation')\n","    plt.xlabel('Frame #')\n","    plt.ylabel(('Processing time per frame [ms]', 'Cumulative processing time [s]')[i])\n","    if i==0:\n","        plt.fill_between(range(T-init_batch),[0]*(T-init_batch),\n","                 [plt.ylim()[1]]*(T-init_batch), where=realtime,\n","                 color='y', alpha=.1, edgecolor='y', zorder=-11, label='real time')\n","        plt.gca().add_artist(plt.legend())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcVTEQhh4REh"},"outputs":[],"source":["cnm1.estimates.A = cnm1.estimates.Ab\n","cnm1.estimates.C = cnm1.estimates.C_on\n","cnm1.estimates.YrA = cnm1.estimates.noisyC-cnm1.estimates.C"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvkZCFPe4REh"},"outputs":[],"source":["cn, pnr = cm.summary_images.correlation_pnr(cm.load(fname), gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n","cnm1.estimates.coordinates = None\n","cnm1.estimates.plot_contours_nb(img=cn, thr=.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2WBPL_I4REh"},"outputs":[],"source":["cnm1.estimates.nb_view_components(img=cn, denoised_color='red', thr=.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlbnU2u74REh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldS7bqeD4REh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cAZ0y-8U4REh"},"source":["## 2. Short initalization phase followed by online processing using OnACID-E"]},{"cell_type":"markdown","metadata":{"id":"daaUJMSq4REh"},"source":["### Record for some seconds\n","The `download_demo` function will download the file (if not already present) and store it inside your caiman_data/example_movies folder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAnUfQiR4REi"},"outputs":[],"source":["init_batch = 500  # number of frames to use for initialization\n","T = 3000          # total number of frames\n","fr = 10           # frame rate (Hz)\n","\n","iterator = get_iterator(fname)\n","\n","m = cm.movie(np.array([next(iterator) for t in range(init_batch)], dtype='float32'))"]},{"cell_type":"markdown","metadata":{"id":"bJXzp5cr4REi"},"source":["### Take a break from imaging to process recorded data\n","Taking a break to keep this demo simple. One could in parallel continue to save the otherwise \"lost\" frames to disk if one was not only intersted in the real-time experiment but post-analysis of the entire session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_-G29-I4REi"},"outputs":[],"source":["fname_init = m.save('init.mmap', order='C')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEm7R-9E4REi"},"outputs":[],"source":["params_dict = {'fnames': fname_init,            # filename(s) to be processed\n","               'fr': fr,                        # frame rate (Hz)\n","               'method_init': 'corr_pnr',       # use corr_pnr for initialization of 1p data\n","               'K': None,                       # upper bound on number of components per patch, in general None\n","               'gSig': (3, 3),                  # gaussian width of a 2D gaussian kernel, which approximates a neuron\n","               'gSiz': (13, 13),                # average diameter of a neuron, in general 4*gSig+1\n","               'merge_thr': .65,                # merging threshold, max correlation allowed\n","               'p': 1,                          # order of the autoregressive system\n","               'tsub': 1,                       # downsampling factor in time for initialization\n","               'ssub': 1,                       # downsampling factor in space for initialization\n","               'only_init': True,               # set it to True to run CNMF-E\n","               'nb': 0,                         # number of background components (rank) if positive,\n","                                                # set it to 0 to use the exact ring model and return background as b0 and W\n","               'min_corr': .65,                 # min peak value from correlation image\n","               'min_pnr': 6,                    # min peak to noise ration from PNR image\n","               'normalize_init': False,         # whether to equalize the movies during initialization\n","               'ring_size_factor': 1.4,         # radius of ring is gSiz*ring_size_factor\n","               'center_psf': True,              # whether to center the Gaussian convolution kernel, set it to True for 1 photon\n","               'init_iter': 1,                  # number of iterations during corr_pnr (1p) initialization\n","               's_min': -10,                    # minimum spike threshold\n","               'init_batch': init_batch,        # length of mini batch for initialization\n","               'init_method': 'cnmf',           # initialization method for initial batch\n","               'batch_update_suff_stat': True,  # flag for updating sufficient statistics (used for updating shapes) in batch\n","               'expected_comps': 600,           # number of expected components\n","               'rval_thr': .55,                 # space correlation threshold\n","               'thresh_fitness_raw': -130,      # threshold for trace SNR\n","               'thresh_fitness_delta': -20,     # threshold for trace SNR\n","               'use_dense': False,              # flag for representation and storing of A and b\n","               'motion_correct': True,          # flag for performing motion correction\n","               'gSig_filt': (3, 3),             # size of high pass spatial filtering, used in 1p data\n","               'use_cnn': False}\n","opts = cnmf.params.CNMFParams(params_dict=params_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NPsbB_WB4REi"},"outputs":[],"source":["cnm2 = cnmf.online_cnmf.OnACID(dview=None, params=opts)\n","cnm2.initialize_online(T=T)"]},{"cell_type":"markdown","metadata":{"id":"KF2sK3mn4REi"},"source":["### Start real-time processing\n","The spatial footprints and background parameters are updated every 200 frames. This results in a long processing time for the individual frames for which these updates occur. Thus instead of the usual waiting for the camera to provide the next image, there are few frames for which the images are acquired faster than processed. We use a separate `Process` to acquire and add the images to a FIFO `Queue` at regular time intervals. The main process reads the next image from this `Queue` and waits for it if the `Queue` is empty."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-vhdF3g4REi"},"outputs":[],"source":["if platform in ('linux', 'darwin'):\n","    \"\"\" This code assumes you are running on a Unix-based computing system (like Linux or macOS)\n","        that allows to start a Process uing a fork() call, NOT Windows. For the latter see the else call below\n","        https://docs.python.org/3.7/library/multiprocessing.html#the-spawn-and-forkserver-start-methods\"\"\"\n","    q = Queue()\n","    cnm2.t_wait = []\n","    cnm2.t_motion = []\n","    cnm2.t_fit = []\n","    realtime = []\n","\n","    def append_to_queue(q, init_batch, T, fr):\n","        t_start = time()\n","        for t in range(init_batch, T):\n","            # read frame and append to queue\n","            frame = next(iterator)\n","            q.put(frame)\n","            sleep(max(0, (t+1-init_batch)/fr - time()+t_start))\n","\n","    producer = Process(target=append_to_queue, args=(q,init_batch,T,fr))\n","    producer.start()\n","\n","    # process first frame\n","    t = init_batch\n","    # read form queue (wait for next frame if empty)\n","    t0=time()\n","    frame = q.get()\n","    cnm2.t_wait.append(time()-t0)\n","    t_start = time() + (1-init_batch)/fr\n","    # motion correct\n","    t0 = time()\n","    frame = cnm2.mc_next(t, frame)\n","    cnm2.t_motion.append(time()-t0)\n","    # fit\n","    t0 = time()\n","    cnm2.fit_next(t, frame.ravel(order='F'))\n","    cnm2.t_fit.append(time()-t0)\n","    rt = time() <= t_start + t/fr\n","    realtime.append(rt)\n","\n","    # process remaining frames\n","    for t in range(init_batch+1, T):\n","        # read form queue (wait for next frame if empty)\n","        t0=time()\n","        frame = q.get()\n","        cnm2.t_wait.append(time()-t0)\n","        # motion correct\n","        t0 = time()\n","        frame = cnm2.mc_next(t, frame)\n","        cnm2.t_motion.append(time()-t0)\n","        # fit\n","        t0 = time()\n","        cnm2.fit_next(t, frame.ravel(order='F'))\n","        cnm2.t_fit.append(time()-t0)\n","        rt = time() <= t_start + t/fr\n","        realtime.append(rt)\n","        # add code to display whatever you want in order to guide the closed-loop experiment below\n","        print('Realtime: ' + (\"\\x1b[32mTrue\\x1b[0m\" if rt else \"\\x1b[31mFalse\\x1b[0m\"), end=\"  \\r\", flush=True)\n","else:\n","\n","    \"\"\"Windows requires as workaround to move some code to the external file 'win.py'.\n","       The new Process is being spawned not forked. Expect performance to be somewhat impeded.\"\"\"\n","    print('Windows lacks os.fork(). Expect performance to be somewhat impeded.')\n","    import win\n","\n","    if __name__ == '__main__':\n","        q = Queue()\n","        cnm2.t_wait = []\n","        cnm2.t_motion = []\n","        cnm2.t_fit = []\n","        realtime = []\n","        producer = Process(target=win.append_to_queue, args=(q,init_batch,T,fr))\n","        producer.start()\n","\n","        # process first frame\n","        t = init_batch\n","        # read form queue (wait for next frame if empty)\n","        t0=time()\n","        frame = q.get()\n","        cnm2.t_wait.append(time()-t0)\n","        t_start = time() + (1-init_batch)/fr\n","        # motion correct\n","        t0 = time()\n","        frame = cnm2.mc_next(t, frame)\n","        cnm2.t_motion.append(time()-t0)\n","        # fit\n","        t0 = time()\n","        cnm2.fit_next(t, frame.ravel(order='F'))\n","        cnm2.t_fit.append(time()-t0)\n","        rt = time() <= t_start + t/fr\n","        realtime.append(rt)\n","\n","        #process remaining frames\n","        for t in range(init_batch+1, T):\n","            # read form queue (wait for next frame if empty)\n","            t0=time()\n","            frame = q.get()\n","            cnm2.t_wait.append(time()-t0)\n","            # motion correct\n","            t0 = time()\n","            frame = cnm2.mc_next(t, frame)\n","            cnm2.t_motion.append(time()-t0)\n","            # fit\n","            t0 = time()\n","            cnm2.fit_next(t, frame.ravel(order='F'))\n","            cnm2.t_fit.append(time()-t0)\n","            rt = time() <= t_start + t/fr\n","            realtime.append(rt)\n","            # add code to display whatever you want in order to guide the closed-loop experiment below\n","            print('Realtime: ' + (\"\\x1b[32mTrue\\x1b[0m\" if rt else \"\\x1b[31mFalse\\x1b[0m\"), end=\"  \\r\", flush=True)\n","        producer.join()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"faw2m1sK4REj"},"outputs":[],"source":["del iterator"]},{"cell_type":"markdown","metadata":{"id":"tUKusR5x4REj"},"source":["### Plot results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QhzXf7Or4REj"},"outputs":[],"source":["print('%g%s processed in real time. %g/%g frames' %\n","      (100 * np.sum(realtime) / (T-init_batch), '%', np.sum(realtime), T-init_batch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qq1nQzid4REj"},"outputs":[],"source":["plt.figure(figsize=(12,4))\n","cnm2.t_read = np.zeros(T-init_batch)\n","for i, f in enumerate((lambda a: 1000*np.array(a), np.cumsum)):\n","    plt.subplot(1,2,1+i)\n","    plt.stackplot(np.arange(len(cnm2.t_fit)), f(cnm2.t_read), f(cnm2.t_motion),\n","                  f(np.array(cnm2.t_fit) - np.array([cnm2.t_detect, cnm2.t_shapes, cnm2.t_stat]).sum(0)),\n","                  f(cnm2.t_detect), f(cnm2.t_shapes)+f(cnm2.t_stat))\n","    plt.gca().add_artist(plt.legend(labels=['read', 'motion', 'process', 'detect', 'shapes'], loc=2))\n","    plt.title('Processing time allocation')\n","    plt.xlabel('Frame #')\n","    plt.ylabel(('Processing time per frame [ms]', 'Cumulative processing time [s]')[i])\n","    if i==0:\n","        plt.ylim(0, 100)\n","        plt.fill_between(range(T-init_batch),[0]*(T-init_batch),\n","                 [100]*(T-init_batch), where=realtime,\n","                 color='y', alpha=.1, edgecolor='y', zorder=-11, label='real time')\n","        plt.gca().add_artist(plt.legend())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPCN-SdL4REj"},"outputs":[],"source":["cnm2.estimates.A = cnm2.estimates.Ab\n","cnm2.estimates.C = cnm2.estimates.C_on[:cnm2.N]\n","cnm2.estimates.YrA = cnm2.estimates.noisyC[:cnm2.N]-cnm2.estimates.C"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyUg7AJt4REm"},"outputs":[],"source":["cn, pnr = cm.summary_images.correlation_pnr(cm.load(fname), gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n","cnm2.estimates.coordinates = None\n","cnm2.estimates.plot_contours_nb(img=cn, thr=.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p17fXH-O4REm"},"outputs":[],"source":["cnm2.estimates.nb_view_components(img=cn, denoised_color='red', thr=.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lp-2WL7X4REm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s89bTU1Y4REm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bu9rTAPj4REm"},"source":["## 3. Short initalization phase followed by online processing using Ring-CNN+OnACID"]},{"cell_type":"markdown","metadata":{"id":"oxIrUKDb4REn"},"source":["### Record for some seconds\n","The `download_demo` function will download the file (if not already present) and store it inside your caiman_data/example_movies folder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UY-UfrOw4REo"},"outputs":[],"source":["init_batch = 500  # number of frames to use for initialization\n","T = 3000          # total number of frames\n","fr = 10           # frame rate (Hz)\n","\n","iterator = get_iterator(fname)\n","\n","m = cm.movie(np.array([next(iterator) for t in range(init_batch)], dtype='float32'))"]},{"cell_type":"markdown","metadata":{"id":"fzxCl3YD4REo"},"source":["### Take a break from imaging to process recorded data\n","Taking a break to keep this demo simple. One could in parallel continue to save the otherwise \"lost\" frames to disk if one was not only intersted in the real-time experiment but post-analysis of the entire session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QeDgvRr4REo"},"outputs":[],"source":["fname_init = m.save('init.mmap', order='C')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCjuaclb4REo"},"outputs":[],"source":["# from caiman.utils.utils import caiman_datadir\n","# reuse_model = True\n","# path_to_model = caiman_datadir() + '/my_logs/run_2023_02_15-18_49_55/model.h5'\n","reuse_model = False                                       # set to True to re-use an existing ring model\n","path_to_model = None                                      # specify a pre-trained model here if needed\n","gSig = (7, 7)                                             # expected half size of neurons\n","gnb = 2                                                   # number of background components for OnACID\n","\n","params_dict = {'fnames': fname_init,                      # filename(s) to be processed\n","               'var_name_hdf5': 'Y',                      # name of variable inside mat file where the data is stored\n","               'fr': fr,                                  # frame rate (Hz)\n","               'decay_time': 0.5,                         # approximate length of transient event in seconds\n","               'gSig': gSig,                              # gaussian width of a 2D gaussian kernel, which approximates a neuron\n","               'p': 1,                                    # order of AR indicator dynamics\n","               'ring_CNN': True,                          # SET TO TRUE TO USE RING CNN\n","               'min_SNR': 2.65,                           # minimum SNR for accepting new components\n","               'SNR_lowest': 0.75,                        # reject components with SNR below this value\n","               'use_cnn': False,                          # do not use CNN based test for components\n","               'use_ecc': True,                           # test eccentricity\n","               'max_ecc': 2.625,                          # reject components with eccentricity above this value\n","               'rval_thr': 0.70,                          # correlation threshold for new component inclusion\n","               'rval_lowest': 0.25,                       # reject components with corr below that value\n","               'ds_factor': 1,                            # spatial downsampling factor (increases speed but may lose some fine structure)\n","               'nb': gnb,                                 # number of background components (rank)\n","               'motion_correct': True,                    # Flag for motion correction\n","               'init_batch': init_batch,                  # number of frames for initialization (presumably from the first file)\n","               'init_method': 'bare',                     # initialization method\n","               'normalize': False,                        # Whether to normalize each frame prior to online processing\n","               'expected_comps': 700,                     # maximum number of expected components used for memory pre-allocation (exaggerate here)\n","               'sniper_mode': False,                      # flag using a CNN to detect new neurons (o/w space correlation is used)\n","               'dist_shape_update' : True,                # flag for updating shapes in a distributed way\n","               'min_num_trial': 5,                        # number of candidate components per frame\n","               'epochs': 1,                               # number of total passes over the data\n","               'stop_detection': False,                   # Run a last epoch without detecting new neurons\n","               'K': 50,                                   # initial number of components\n","               'lr': 6e-4,                                # (initial) learning rate\n","               'lr_scheduler': [0.9, 6000, 10000],        # learning rate scheduler\n","               'pct': 0.01,                               # quantile of the quantile loss function\n","               'path_to_model': path_to_model,            # where the ring CNN model is saved/loaded\n","               'reuse_model': reuse_model,                # flag for re-using a ring CNN model\n","              }\n","opts = cnmf.params.CNMFParams(params_dict=params_dict)"]},{"cell_type":"markdown","metadata":{"id":"qMwiHRIo4REo"},"source":["#### Train or load Ring CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sOhEcIv4REo"},"outputs":[],"source":["cnm3 = cnmf.online_cnmf.OnACID(params=opts)\n","\n","if cnm3.params.get('ring_CNN', 'loss_fn') == 'pct':\n","    loss_fn = quantile_loss(cnm3.params.get('ring_CNN', 'pct'))\n","else:\n","    loss_fn = cnm3.params.get('ring_CNN', 'loss_fn')\n","if cnm3.params.get('ring_CNN', 'lr_scheduler') is None:\n","    sch = None\n","else:\n","    sch = rate_scheduler(*cnm3.params.get('ring_CNN', 'lr_scheduler'))\n","model_LN = create_LN_model(m, shape=m.shape[1:] + (1,),\n","                           n_channels=cnm3.params.get('ring_CNN', 'n_channels'),\n","                           lr=cnm3.params.get('ring_CNN', 'lr'),\n","                           gSig=cnm3.params.get('init', 'gSig')[0],\n","                           loss=loss_fn, width=cnm3.params.get('ring_CNN', 'width'),\n","                           use_add=cnm3.params.get('ring_CNN', 'use_add'),\n","                           use_bias=cnm3.params.get('ring_CNN', 'use_bias'))\n","if cnm3.params.get('ring_CNN', 'reuse_model'):\n","    model_LN.load_weights(cnm3.params.get('ring_CNN', 'path_to_model'))\n","else:\n","    model_LN, history, path_to_model = fit_NL_model(\n","        model_LN, m, epochs=cnm3.params.get('ring_CNN', 'max_epochs'),\n","        patience=cnm3.params.get('ring_CNN', 'patience'), schedule=sch)\n","    cnm3.params.set('ring_CNN', {'path_to_model': path_to_model})"]},{"cell_type":"markdown","metadata":{"id":"C2MF9gEt4REo"},"source":["#### Initialize OnACID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUYoVgWN4REo"},"outputs":[],"source":["cnm3.initialize_online(T=T, model_LN=model_LN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBXwHgts4REo"},"outputs":[],"source":["# if no GPU is available prediction is faster when the CNN is converted into a sparse matrix\n","if False:#tf.test.is_gpu_available():\n","    predict = model_LN.predict\n","    # dummy prediction to initialize CNN-ring model model_LN\n","    predict(m[:1, ..., None])\n","else:\n","    dims = m[0].shape\n","    kernel_size = model_LN.layers[1].weights[0].shape[0]\n","    kernel_half = (kernel_size-1)//2\n","    w_1 = model_LN.layers[1].weights[0].numpy().squeeze().transpose(2,0,1)\n","    w_1 = w_1.reshape(len(w_1), -1)\n","    w_2 = model_LN.layers[2].weights[0].numpy()\n","    data = []\n","    indices = []\n","    indptr = [0]\n","    for i in range(dims[0]):\n","        for j in range(dims[1]):\n","            tmp = np.zeros((dims[0]+kernel_size, dims[1]+kernel_size), dtype=np.float32)\n","            tmp[i:i+kernel_size, j:j+kernel_size] = w_2[i, j].dot(w_1).reshape(kernel_size, kernel_size)\n","            tmp = tmp[kernel_half:kernel_half+dims[0], kernel_half:kernel_half+dims[1]].ravel()\n","            ind = np.where(tmp!=0)[0]\n","            newdata = list(tmp[ind])\n","            data += newdata\n","            indices += list(ind)\n","            indptr += [len(newdata) + indptr[-1]]\n","    w = csr_matrix((data, indices, indptr)).todia()\n","\n","    def predict(frame):\n","        return w.dot(frame.ravel()).reshape(dims)"]},{"cell_type":"markdown","metadata":{"id":"oIU_9sHh4REo"},"source":["### Start real-time processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8c4bBqRa4REo"},"outputs":[],"source":["cnm3.t_read = []\n","cnm3.t_bkgrd = []\n","cnm3.t_motion = []\n","cnm3.t_fit = []\n","for t in range(init_batch, T):\n","    # read frame\n","    t0 = time()\n","    frame = next(iterator)\n","    cnm3.t_read.append(time()-t0)\n","    # remove background\n","    t0 = time()\n","    frame = np.maximum(frame - np.squeeze(predict(\n","        frame.astype(np.float32)[None,...,None])), 0)\n","    cnm3.t_bkgrd.append(time()-t0)\n","    # motion correct\n","    t0 = time()\n","    frame = cnm3.mc_next(t, frame.astype(np.float32))\n","    cnm3.t_motion.append(time()-t0)\n","    # fit\n","    t0 = time()\n","    cnm3.fit_next(t, frame.ravel(order='F'))\n","    cnm3.t_fit.append(time()-t0)\n","    # add code to display whatever you want in order to guide the closed-loop experiment below"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ozx3lkoh4REo"},"outputs":[],"source":["del iterator"]},{"cell_type":"markdown","metadata":{"id":"Q-EQdl_W4REp"},"source":["### Plot results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vp3xvCDi4REp"},"outputs":[],"source":["# calculate time one would have to wait for next frame to arrive if reading directly from camera\n","t_all = np.cumsum(cnm3.t_read) + np.cumsum(cnm3.t_bkgrd) + np.cumsum(cnm3.t_motion) + np.cumsum(cnm3.t_fit)\n","\n","t_wait=[1]\n","t_wait_total=0\n","for i in range(1, T-init_batch):\n","    t_wait.append(max(i/fr - t_all[i-1]-t_wait_total, 0))\n","    t_wait_total += t_wait[-1]\n","realtime = np.array(t_wait)>0\n","print('%g%s processed in real time. %g/%g frames' %\n","      (100 * realtime.sum() / (T-init_batch), '%', realtime.sum(), T-init_batch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMszBbnf4REp"},"outputs":[],"source":["plt.figure(figsize=(12,4))\n","for i, f in enumerate((lambda a: 1000*np.array(a), np.cumsum)):\n","    plt.subplot(1,2,1+i)\n","    plt.stackplot(np.arange(len(cnm3.t_fit)), f(cnm3.t_read), f(cnm3.t_bkgrd), f(cnm3.t_motion),\n","                  f(np.array(cnm3.t_fit) - np.array([cnm3.t_detect, cnm3.t_shapes, cnm3.t_stat]).sum(0)),\n","                  f(cnm3.t_detect), f(cnm3.t_shapes)+f(cnm3.t_stat))\n","    plt.gca().add_artist(plt.legend(labels=['read', 'background', 'motion', 'process', 'detect', 'shapes'], loc=2))\n","    plt.title('Processing time allocation')\n","    plt.xlabel('Frame #')\n","    plt.ylabel(('Processing time per frame [ms]', 'Cumulative processing time [s]')[i])\n","    if i==0:\n","        plt.fill_between(range(T-init_batch),[0]*(T-init_batch),\n","                 [plt.ylim()[1]]*(T-init_batch), where=realtime,\n","                 color='y', alpha=.1, edgecolor='y', zorder=-11, label='real time')\n","        plt.gca().add_artist(plt.legend())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ALUZ17T4REp"},"outputs":[],"source":["cnm3.estimates.A = cnm3.estimates.Ab[:,gnb:]\n","cnm3.estimates.C = cnm3.estimates.C_on[gnb:cnm3.M]\n","cnm3.estimates.YrA = cnm3.estimates.noisyC[gnb:cnm3.M]-cnm3.estimates.C"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBQJEr8a4REp"},"outputs":[],"source":["cn, pnr = cm.summary_images.correlation_pnr(cm.load(fname), gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n","cnm3.estimates.coordinates = None\n","cnm3.estimates.plot_contours_nb(img=cn, thr=.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"k06rnTIg4REp"},"outputs":[],"source":["cnm3.estimates.nb_view_components(img=cn,denoised_color='red', thr=.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SbYdB-Enf5Yg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSJwHpiF4REp"},"outputs":[],"source":["# running with CNN converted into a sparse matrix can be faster if GPU is slow\n","iterator = get_iterator(fname)\n","m = cm.movie(np.array([next(iterator) for t in range(init_batch)], dtype='float32'))\n","\n","cnm3 = cnmf.online_cnmf.OnACID(params=opts)\n","cnm3.initialize_online(T=T, model_LN=model_LN)\n","\n","cnm3.t_read = []\n","cnm3.t_bkgrd = []\n","cnm3.t_motion = []\n","cnm3.t_fit = []\n","for t in range(init_batch, T):\n","    # read frame\n","    t0 = time()\n","    frame = next(iterator)\n","    cnm3.t_read.append(time()-t0)\n","    # remove background\n","    t0 = time()\n","    frame = np.maximum(frame - np.squeeze(predict(\n","        frame.astype(np.float32)[None,...,None])), 0)\n","    cnm3.t_bkgrd.append(time()-t0)\n","    # motion correct\n","    t0 = time()\n","    frame = cnm3.mc_next(t, frame.astype(np.float32))\n","    cnm3.t_motion.append(time()-t0)\n","    # fit\n","    t0 = time()\n","    cnm3.fit_next(t, frame.ravel(order='F'))\n","    cnm3.t_fit.append(time()-t0)\n","    # add code to display whatever you want in order to guide the closed-loop experiment below\n","\n","del iterator\n","\n","# calculate time one would have to wait for next frame to arrive if reading directly from camera\n","t_all = np.cumsum(cnm3.t_read) + np.cumsum(cnm3.t_bkgrd) + np.cumsum(cnm3.t_motion) + np.cumsum(cnm3.t_fit)\n","t_wait=[1]\n","t_wait_total=0\n","for i in range(1, T-init_batch):\n","    t_wait.append(max(i/fr - t_all[i-1]-t_wait_total, 0))\n","    t_wait_total += t_wait[-1]\n","realtime = np.array(t_wait)>0\n","print('%g%s processed in real time. %g/%g frames' %\n","      (100 * realtime.sum() / (T-init_batch), '%', realtime.sum(), T-init_batch))\n","\n","plt.figure(figsize=(12,4))\n","for i, f in enumerate((lambda a: 1000*np.array(a), np.cumsum)):\n","    plt.subplot(1,2,1+i)\n","    plt.stackplot(np.arange(len(cnm3.t_fit)), f(cnm3.t_read), f(cnm3.t_bkgrd), f(cnm3.t_motion),\n","                  f(np.array(cnm3.t_fit) - np.array([cnm3.t_detect, cnm3.t_shapes, cnm3.t_stat]).sum(0)),\n","                  f(cnm3.t_detect), f(cnm3.t_shapes)+f(cnm3.t_stat))\n","    plt.gca().add_artist(plt.legend(labels=['read', 'background', 'motion', 'process', 'detect', 'shapes'], loc=2))\n","    plt.title('Processing time allocation')\n","    plt.xlabel('Frame #')\n","    plt.ylabel(('Processing time per frame [ms]', 'Cumulative processing time [s]')[i])\n","    if i==0:\n","        plt.fill_between(range(T-init_batch),[0]*(T-init_batch),\n","                 [plt.ylim()[1]]*(T-init_batch), where=realtime,\n","                 color='y', alpha=.1, edgecolor='y', zorder=-11, label='real time')\n","        plt.gca().add_artist(plt.legend())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kg7PA3iXgif0"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"10XvY5fjJOMioubmjoZWIM5N2gOWkHvO4","timestamp":1699049724598},{"file_id":"1MpRYWyC7-TI9FA0dK1S7Kx40TLVwd3cz","timestamp":1676410968357}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat":4,"nbformat_minor":0}