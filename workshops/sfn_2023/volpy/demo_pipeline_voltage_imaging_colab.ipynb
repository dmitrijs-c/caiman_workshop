{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Demo VolPy pipeline for processing voltage imaging data\n",
        "The processing pipeline\n",
        "includes **motion correction**, **memory mapping**, **segmentation**, **denoising and source\n",
        "extraction**.\n",
        "\n",
        "The demo shows how to construct the params, MotionCorrect and VOLPY\n",
        "objects and call the relevant functions.\n",
        "\n",
        "Dataset is by courtesy of Karel Svoboda Lab (Janelia Research Campus).\n",
        "\n",
        "Check VolPy paper for more detail: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008806\n"
      ],
      "metadata": {
        "id": "GUORcMoeEbYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install CaImAn and relevant packages"
      ],
      "metadata": {
        "id": "L1z3j3jFFOTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG-Rn32_IIR7"
      },
      "outputs": [],
      "source": [
        "# Clone CaImAn from Github\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd /content/CaImAn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp-HtoSqIW6S"
      },
      "outputs": [],
      "source": [
        "# Install relevant packages\n",
        "!pip install -r requirements.txt\n",
        "! pip install imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNSMw3ylIZSo"
      },
      "outputs": [],
      "source": [
        "# Install CaImAn package\n",
        "!pip install -e .\n",
        "# Install CaImAn manager for relevant datasets\n",
        "! caimanmanager install --inplace"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages"
      ],
      "metadata": {
        "id": "nK1STmOEFZxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "NzHIeSOVHRm3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import logging\n",
        "from matplotlib import markers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import imageio\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "from base64 import b64encode\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    if __IPYTHON__:\n",
        "        # this is used for debugging purposes only. allows to reload classes\n",
        "        # when changed\n",
        "        get_ipython().magic('load_ext autoreload')\n",
        "        get_ipython().magic('autoreload 2')\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.utils.utils import download_demo, download_model\n",
        "from caiman.source_extraction.volpy import utils\n",
        "from caiman.source_extraction.volpy.volparams import volparams\n",
        "from caiman.source_extraction.volpy.volpy import VOLPY\n",
        "from caiman.source_extraction.volpy.mrcnn import visualize, neurons\n",
        "import caiman.source_extraction.volpy.mrcnn.model as modellib\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from caiman.summary_images import mean_image\n",
        "from caiman.paths import caiman_datadir\n",
        "\n",
        "# Set up the logger (optional); change this if you like.\n",
        "# You can log to a file using the filename parameter, or make the output more\n",
        "# or less verbose by setting level to logging.DEBUG, logging.INFO,\n",
        "# logging.WARNING, or logging.ERROR\n",
        "logging.basicConfig(format=\n",
        "                    \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s]\" \\\n",
        "                    \"[%(process)d] %(message)s\",\n",
        "                    level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download movies and setup volpy parameters for motion correction"
      ],
      "metadata": {
        "id": "wmqFsSCgFpkA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW54aHS_HRnE"
      },
      "outputs": [],
      "source": [
        "# Download movies\n",
        "fnames = download_demo('demo_voltage_imaging.hdf5', 'volpy')\n",
        "path_ROIs = download_demo('demo_voltage_imaging_ROIs.hdf5', 'volpy')\n",
        "\n",
        "# Setup some parameters for data and motion correction dataset parameters\n",
        "fr = 400                                        # sample rate of the movie\n",
        "ROIs = None                                     # Region of interests\n",
        "index = None                                    # index of neurons\n",
        "weights = None                                  # reuse spatial weights by\n",
        "                                                # opts.change_params(params_dict={'weights':vpy.estimates['weights']})\n",
        "pw_rigid = False                                # flag for pw-rigid motion correction\n",
        "gSig_filt = (3, 3)                              # size of filter, in general gSig (see below),\n",
        "                                                # change this one if algorithm does not work\n",
        "max_shifts = (5, 5)                             # maximum allowed rigid shift\n",
        "strides = (48, 48)                              # start a new patch for pw-rigid motion correction every x pixels\n",
        "overlaps = (24, 24)                             # overlap between pathes (size of patch strides+overlaps)\n",
        "max_deviation_rigid = 3                         # maximum deviation allowed for patch with respect to rigid shifts\n",
        "border_nan = 'copy'\n",
        "\n",
        "opts_dict = {\n",
        "    'fnames': fnames,\n",
        "    'fr': fr,\n",
        "    'index': index,\n",
        "    'ROIs': ROIs,\n",
        "    'weights': weights,\n",
        "    'pw_rigid': pw_rigid,\n",
        "    'max_shifts': max_shifts,\n",
        "    'gSig_filt': gSig_filt,\n",
        "    'strides': strides,\n",
        "    'overlaps': overlaps,\n",
        "    'max_deviation_rigid': max_deviation_rigid,\n",
        "    'border_nan': border_nan\n",
        "}\n",
        "\n",
        "opts = volparams(params_dict=opts_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HqUNdCyPBBW"
      },
      "outputs": [],
      "source": [
        "# Display the movie\n",
        "# save the movie in the .mp4 format\n",
        "m_orig = cm.load(fnames)\n",
        "ds_ratio = 0.2\n",
        "moviehandle = m_orig.resize(1, 1, ds_ratio)\n",
        "min_, max_ = np.min(moviehandle), np.max(moviehandle)\n",
        "moviehandle = np.array((moviehandle-min_)/(max_-min_)*255,dtype='uint8')\n",
        "imageio.mimwrite('/root/caiman_data/raw_movie.mp4', moviehandle , fps = 60, quality=8)\n",
        "\n",
        "# play the movie\n",
        "mp4 = open('/root/caiman_data/raw_movie.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6wKKAaeK1V_"
      },
      "outputs": [],
      "source": [
        "# Start a cluster for parallel processing\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motion correction"
      ],
      "metadata": {
        "id": "bb-M-_VOF3Gl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQBBg_xb13rp"
      },
      "outputs": [],
      "source": [
        "# Create a motion correction object with the specified parameters\n",
        "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
        "# Run piecewise rigid motion correction\n",
        "mc.motion_correct(save_movie=True)\n",
        "dview.terminate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ8BDHESHRnh"
      },
      "outputs": [],
      "source": [
        "# Motion corrected movie compared with original movie\n",
        "m_orig = cm.load(fnames)\n",
        "m_rig = cm.load(mc.mmap_file)\n",
        "m_orig.fr = 400\n",
        "m_rig.fr = 400\n",
        "ds_ratio = 0.2\n",
        "moviehandle = cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov * mc.nonneg_movie,\n",
        "                              m_rig.resize(1, 1, ds_ratio)], axis=2)\n",
        "min_, max_ = np.min(moviehandle), np.max(moviehandle)\n",
        "moviehandle = np.array((moviehandle-min_)/(max_-min_)*255,dtype='uint8')\n",
        "imageio.mimwrite('/root/caiman_data/motion_correction_movie.mp4', moviehandle , fps = 60, quality=8)\n",
        "\n",
        "mp4 = open('/root/caiman_data/motion_correction_movie.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=600 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdeR6igh2cAd"
      },
      "outputs": [],
      "source": [
        "# Motion corrected movie (first 1000 frames) subtracted from the baseline\n",
        "m_rig2 = m_rig.computeDFF(secsWindow=1)[0][:1000]\n",
        "moviehandle1 = -m_rig2\n",
        "min_, max_ = np.min(moviehandle1), np.max(moviehandle1)\n",
        "moviehandle1 = np.array((moviehandle1-min_)/(max_-min_)*255,dtype='uint8')\n",
        "imageio.mimwrite('/root/caiman_data/motion_correction_bl_movie.mp4', moviehandle1 , fps = 60, quality=8)\n",
        "\n",
        "mp4 = open('/root/caiman_data/motion_correction_bl_movie.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=300 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the inferred motion shifts\n",
        "plt.figure()\n",
        "plt.plot(mc.shifts_rig)\n",
        "plt.ylabel('Shifts (pixels)')\n",
        "plt.xlabel('Frames')\n",
        "plt.legend(['Vertical shift', 'Horizontal shift'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hv7LjOYhByJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Mapping"
      ],
      "metadata": {
        "id": "p0xe_YnPF5Nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpJDa20bHRnp"
      },
      "outputs": [],
      "source": [
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)\n",
        "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0\n",
        "fname_new = cm.save_memmap_join(mc.mmap_file, base_name='memmap_',\n",
        "                           add_to_mov=border_to_0, dview=dview, n_chunks=10)\n",
        "dview.terminate()\n",
        "\n",
        "# change fnames to the new motion corrected one\n",
        "opts.change_params(params_dict={'fnames': fname_new})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLSPvv5Nt-u-"
      },
      "outputs": [],
      "source": [
        "if 'dview' in locals():\n",
        "    cm.stop_server(dview=dview)\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation"
      ],
      "metadata": {
        "id": "dYfkl3tbF8sz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBTRlgBunb4Q"
      },
      "outputs": [],
      "source": [
        "# Create summary images\n",
        "img = mean_image(mc.mmap_file[0], window = 1000, dview=dview)\n",
        "img = (img-np.mean(img))/np.std(img)\n",
        "\n",
        "gaussian_blur = False        # Use gaussian blur when there is too much noise in the video\n",
        "Cn = local_correlations_movie_offline(mc.mmap_file[0], fr=fr, window=fr*4,\n",
        "                                      stride=fr*4, winSize_baseline=fr,\n",
        "                                      remove_baseline=True, gaussian_blur=gaussian_blur,\n",
        "                                      dview=dview).max(axis=0)\n",
        "img_corr = (Cn-np.mean(Cn))/np.std(Cn)\n",
        "summary_images = np.stack([img, img, img_corr], axis=0).astype(np.float32)\n",
        "\n",
        "# Save summary images which are used in the VolPy GUI\n",
        "cm.movie(summary_images).save(fnames[:-5] + '_summary_images.tif')\n",
        "\n",
        "# Visualization\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].imshow(summary_images[0]); axs[1].imshow(summary_images[2])\n",
        "axs[0].set_title('mean image'); axs[1].set_title('corr image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUDya-p2HRnu"
      },
      "outputs": [],
      "source": [
        "# Perform segmentation\n",
        "use_maskrcnn = True  # set to True to predict the ROIs using the mask R-CNN\n",
        "if not use_maskrcnn:                 # use manual annotations\n",
        "    with h5py.File(path_ROIs, 'r') as fl:\n",
        "        ROIs = fl['mov'][()]  # load ROIs\n",
        "else:\n",
        "    weights_path = download_model('mask_rcnn')\n",
        "    ROIs = utils.mrcnn_inference(img=summary_images.transpose([1, 2, 0]), size_range=[5, 22],\n",
        "                                  weights_path=weights_path, display_result=True) # size parameter decides size range of masks to be selected\n",
        "    cm.movie(ROIs).save(fnames[:-5] + '_mrcnn_ROIs.hdf5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].imshow(summary_images[0])\n",
        "axs[1].imshow(ROIs.sum(0))\n",
        "axs[0].set_title('mean image')\n",
        "axs[1].set_title('masks')\n",
        "print(f'ROIs shape: {ROIs.shape}')"
      ],
      "metadata": {
        "id": "vKFZC-krDwVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z92CC4631AA"
      },
      "outputs": [],
      "source": [
        "# Restart cluster to clean up memory\n",
        "cm.stop_server(dview=dview)\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False, maxtasksperchild=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trace denoising and spike extraction"
      ],
      "metadata": {
        "id": "eD-3JGH7GIsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCNTy-LZHRn6"
      },
      "outputs": [],
      "source": [
        "# Setup parameters for trace denoising and spike extraction\n",
        "ROIs = ROIs                                   # region of interests\n",
        "index = list(range(len(ROIs)))                # index of neurons\n",
        "weights = None                                # if None, use ROIs for initialization; to reuse weights check reuse weights block\n",
        "\n",
        "template_size = 0.02                          # half size of the window length for spike templates, default is 20 ms\n",
        "context_size = 35                             # number of pixels surrounding the ROI to censor from the background PCA\n",
        "visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
        "flip_signal = True                            # Important!! Flip signal or not, True for Voltron indicator, False for others\n",
        "hp_freq_pb = 1 / 3                            # parameter for high-pass filter to remove photobleaching\n",
        "clip = 100                                    # maximum number of spikes to form spike template\n",
        "threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple\n",
        "min_spikes= 10                                # minimal spikes to be found\n",
        "pnorm = 0.5                                   # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
        "threshold = 3                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
        "do_plot = False                               # plot detail of spikes, template for the last iteration\n",
        "ridge_bg= 0.01                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization\n",
        "sub_freq = 20                                 # frequency for subthreshold extraction\n",
        "weight_update = 'ridge'                       # ridge or NMF for weight update\n",
        "n_iter = 2                                    # number of iterations alternating between estimating spike times and spatial filters\n",
        "\n",
        "opts_dict={'fnames': fname_new,\n",
        "            'ROIs': ROIs,\n",
        "            'index': index,\n",
        "            'weights': weights,\n",
        "            'template_size': template_size,\n",
        "            'context_size': context_size,\n",
        "            'visualize_ROI': visualize_ROI,\n",
        "            'flip_signal': flip_signal,\n",
        "            'hp_freq_pb': hp_freq_pb,\n",
        "            'clip': clip,\n",
        "            'threshold_method': threshold_method,\n",
        "            'min_spikes':min_spikes,\n",
        "            'pnorm': pnorm,\n",
        "            'threshold': threshold,\n",
        "            'do_plot':do_plot,\n",
        "            'ridge_bg':ridge_bg,\n",
        "            'sub_freq': sub_freq,\n",
        "            'weight_update': weight_update,\n",
        "            'n_iter': n_iter}\n",
        "\n",
        "opts.change_params(params_dict=opts_dict);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAm_iznuHRoA"
      },
      "outputs": [],
      "source": [
        "# Perform trace denoising and spike extraction\n",
        "vpy = VOLPY(n_processes=n_processes, dview=dview, params=opts)\n",
        "vpy.fit(n_processes=n_processes, dview=dview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9Otq9-hJMMj"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "indexes = np.where(vpy.estimates['locality'])[0]\n",
        "\n",
        "for i in range(len(indexes)):\n",
        "  fig = plt.figure(constrained_layout=True,figsize=(16,6))\n",
        "  gs = fig.add_gridspec(1, 3)\n",
        "  ax1 = fig.add_subplot(gs[:1])\n",
        "  ax2 = fig.add_subplot(gs[1:])\n",
        "  #ax1.imshow(ROIs[indexes][i])\n",
        "\n",
        "  spatial = vpy.estimates['weights'][indexes][i].copy()\n",
        "  ax1.imshow(img_corr, interpolation='None', cmap=plt.cm.gray, vmax=np.percentile(img_corr, 98))\n",
        "  spatial[spatial == 0] = np.nan\n",
        "  ax1.imshow(spatial, interpolation='None',\n",
        "            alpha=0.5, cmap=plt.cm.hot)\n",
        "  ax1.set_title(f'neuron {indexes[i]}')\n",
        "  plt.axis('off')\n",
        "  ax2.plot(vpy.estimates['t'][indexes][i])\n",
        "  ax2.plot(vpy.estimates['spikes'][indexes][i],\n",
        "          np.max(vpy.estimates['t'][indexes][i]) * np.ones(vpy.estimates['spikes'][indexes][i].shape),\n",
        "          color='r', marker='.', markersize=5, fillstyle='none', linestyle='none')\n",
        "  ax2.legend(['trace', 'spikes'])\n",
        "\n",
        "  display(fig)\n",
        "  clear_output(wait=True)\n",
        "  plt.pause(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv9zCNpbHRoO"
      },
      "outputs": [],
      "source": [
        "# Stop clusters and clean up log files\n",
        "cm.stop_server(dview=dview)\n",
        "log_files = glob.glob('*_LOG_*')\n",
        "for log_file in log_files:\n",
        "    os.remove(log_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}